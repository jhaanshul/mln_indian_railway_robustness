# -*- coding: utf-8 -*-
"""MLN_PROJECT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gndzynPU36OXmrDVIqOhn7QLu0KU1rxK
"""

from google.colab import drive
drive.mount('/content/gdrive')

import random
import networkx as nx
import collections
import matplotlib.pyplot as plt
import numpy
import math
from matplotlib import pyplot as plt

def isLocalTrain(lines, i, cur_train):    #checks whether the cur_train is a local train or express
  temp = cur_train
  while(temp==cur_train and i < len(lines)-1):
    i+=1
    if(lines[i].split(",")[0]!="K"):
      cur_train = lines[i].split(",")[0]
  distance_travelled = None
  try:
    distance_travelled = int(lines[i-1].split(",")[7])
    if(distance_travelled < 250):
      return (True, i)
  except:
    print("inside: "+lines[i-1])
  return (False, None)

# def remove_local_train_from_graph(G, pos, lines, train):
#   last_train = None
#   cur_train = None
#   cur_station = None
#   cur_distance = None
#   last_station = None
#   last_distance = None
#   for i in range(pos, 0, -1):
#     l = lines[i]
#     l = l.split(",")
#     if(l[0]=="K"):  ##some entries in the csv have improper entries 
#       continue
#     cur_train = l[0]
#     cur_station = l[3]
#     if(cur_train==last_train):
#       G.remove_edge(cur_station, last_station)
#     elif(last_train!=None):
#       return
#     last_train = cur_train
#     last_station = cur_station

trains = set()
with open('/content/gdrive/My Drive/MLN_Project/Train_details_22122017.csv') as f:
  lines = f.readlines()[1:]
  for i in range(len(lines)):
    l = lines[i]
    l = l.split(",")
    if(l[0]=="K"):  ##some entries in the csv have improper entries 
      continue
    cur_train = l[0]
    trains.add(cur_train)

len(trains)

"""#below code for generating the graph. Local trains are not included in the network for better clarity of the network."""

G = nx.DiGraph()
locals = 0
edge_to_train_map = {}   #contains the list of trains passing throug each edge
train_details_map = {}   #contains the loss related to each train as the log of the distance covered by it

with open('/content/gdrive/My Drive/MLN_Project/Train_details_22122017.csv') as f:
  lines = f.readlines()[1:]
  last_train = None
  cur_train = None
  cur_station = None
  cur_distance = None
  last_station = None
  last_distance = None
  for i in range(len(lines)):
    l = lines[i]
    l = l.split(",")
    if(l[0]=="K"):  ##some entries in the csv have improper entries 
      continue
    cur_train = l[0]
    cur_station = l[3]
    (isLocal, index) = isLocalTrain(lines, i, cur_train)
    if(isLocal):
      locals += 1
      i = index
      continue

    try:
      cur_distance = int(l[7])
    except:
      print("exception :"+ str(l))
    
    if(cur_train==last_train):
      edge_data = G.get_edge_data(last_station, cur_station)
      count = 1 if edge_data==None else (edge_data['weight'] + 1)
      G.add_edge(last_station,cur_station, weight = count)
      if((last_station, cur_station) in edge_to_train_map):
        edge_to_train_map[(last_station, cur_station)].append(cur_train)
      else:
        trains = []
        trains.append(cur_train)
        edge_to_train_map[(last_station, cur_station)] = trains

    else:
      # if(last_distance!=None and last_distance < 250 ):
      #   #remove_local_train_from_graph(G, i-1, lines, last_train)
      #   locals += 1
      # else:
        try:
          train_details_map[last_train] = math.log(last_distance)
        except:
          print(last_distance)
    last_train = cur_train
    last_station = cur_station
    last_distance = cur_distance

G.number_of_nodes()

G.number_of_edges()

# def plot_degree_sequence(graphs): #takes input as a dictionary with key as graph and value as the color in plot
#   for G in graphs.keys():
#     degree_sequence = sorted([d for n, d in G.degree()], reverse=False)
#     d = {} #dictionary for maintaing the count of each degree
#     for deg in degree_sequence:
#       if deg in d:
#         d[deg] = d[deg] + 1
#       else:
#         d[deg] = 1
#     y = numpy.log10(list(d.values()))
#     x = numpy.log10(list(d.keys()))
#     plt.plot(x,y, color=graphs[G])
#   plt.xlabel('degree log')
#   plt.ylabel('count log')
#   plt.title('Degree Distribution')
#   plt.show()

# plot_degree_sequence({G: 'red'})

def plot_degree_sequence(G):
  degree_sequence = sorted([d for n, d in G.out_degree()], reverse=False)
  d = {}
  for deg in degree_sequence:
    if deg in d:
      d[deg] = d[deg] + 1
    else:
      d[deg] = 1
  y = numpy.log10(list(d.values()))
  x = numpy.log10(list(d.keys()))
  # par = numpy.polyfit( x[1:], y[1:], 1, full=True )
  # c=par[0][1]
  # m=par[0][0]
  # yfit = [c + m * xi for xi in x]
  plt.scatter(x,y, color='green')
  #plt.plot(x,yfit)
  plt.xlabel('degree log')
  plt.ylabel('count log')
  plt.title('Degree Distribution')
  plt.show()

plot_degree_sequence(G)

plot_degree_sequence(G)

"""Following section implements the influenece maximization algorithm for retrieving the most relevant edges in the network"""

def total_loss(train_details_map):
  values = train_details_map.values()
  sum = 0
  for v in values:
    sum += v
  return sum

total_loss_ = total_loss(train_details_map)   #total_loss_ stroring the total loss if all trains are stopped running

total_loss_

def get_edge_loss(edge, cur_set, train_details_map, edge_to_train_map):
  loss = 0
  for train in edge_to_train_map[edge]:
    if(train not in cur_set):
      try:
        loss += train_details_map[train]
      except:
        loss += 0
  return loss

def maximize_influence(G, k , train_details_map, edge_to_train_map):
  cur_set = set()
  total_loss = 0
  result = []
  for i in range(k):
    max_edge = None
    max_loss = 0
    for edge in G.edges():
      edge_loss = get_edge_loss(edge, cur_set, train_details_map, edge_to_train_map)
      if(edge_loss > max_loss):
        max_edge = edge
        max_loss = edge_loss
    #print(max_edge)
    total_loss += max_loss
    result.append(total_loss)
    try:
      cur_set.update(set(edge_to_train_map[max_edge])) #add to the set, the list of train destroyed through 
      G.remove_edge(max_edge[0], max_edge[1])
    except:
      x = 0
  return result

result = maximize_influence(G.copy(), 1000, train_details_map, edge_to_train_map)

percentage = 75

def get_x_value(percentage, max_value, result_list):
    percent_value = (percentage/100) * max_value
    index = next(x[0] for x in enumerate(result_list) if x[1] >= percent_value)
    return index+1, percent_value

x_value, y_value = get_x_value(percentage, total_loss_, result)

def plot(result, percentage, total_loss_):
  x_value, y_value = get_x_value(percentage, total_loss_, result)
  plt.plot(range(len(result)),result, color='green')
  plt.axvline(x=x_value, color='r', linestyle='--')
  plt.axhline(y=y_value, color='r', linestyle='--')
  x_pos = 0.3*len(result)
  y_pos = 0.3*len(result)

  plt.text(x_pos, y_pos, str(percentage)+"% damage on removal of "+str(x_value)+" edges")

  plt.xlabel('Edges')
  plt.ylabel('Loss')
  plt.title('Robustness')
  plt.show()

plot(result, 75, total_loss_)

def maximize_influence_based_on_central_nodes(G, nodes):
  cur_set = set()
  total_loss = 0
  result = []
  for node in nodes:
    edges = list(G.edges(node))
    for edge in edges:
      edge_loss = get_edge_loss(edge, cur_set, train_details_map, edge_to_train_map)
      total_loss += edge_loss
      result.append(total_loss)
      try:
        cur_set.update(set(edge_to_train_map[edge])) #add to the set, the list of train destroyed through 
        G.remove_edge(edge[0], edge[1])
      except:
        x = 0
  return result

top_forty_stations = ['MGS','BZA','BPQ','BSL','HBJ','CNB','JHS','NDLS','VZM','SC','STA','NGP','HWH','NJP','PPTA','BBS','ADI','KOTA','BSR','PUNE','KYN','BSP','MAS','SA','NBQ','SUR','BRC','BJU','GTL','LKO','MLDT','BSB','TATA','RN','ALD','KIR','PNVL','GHY','DEE','MAO']

top_sixty_stations = ['BSL', 'MGS', 'BPQ', 'SC', 'HBJ', 'BZA', 'NDLS', 'STA', 'VZM', 'ALD', 'GTL', 'BBS', 'PPTA', 'DEE', 'CAR', 'CSN', 'ARW', 'HWH', 'IGP', 'NJP', 'BJU', 'BSB', 'WR', 'LTT', 'MAS', 'BPRD', 'SA', 'ADI', 'KGP', 'BTI', 'SLO', 'RU', 'JU', 'ADRA', 'DLI', 'KCG', 'TATA', 'BSR', 'RN', 'JHS', 'NZM', 'ASR', 'BJF', 'ABR', 'NBQ', 'LNL', 'GMO', 'JSME', 'BTE', 'KIR', 'GHY', 'HMH', 'LDH', 'BKN', 'BGS', 'NGP', 'MDU', 'FL', 'YPR', 'SOG']

top_hundred_stations = ['BSL', 'MGS', 'BPQ', 'SC', 'HBJ', 'BZA', 'NDLS', 'STA', 'VZM', 'ALD', 'GTL', 'BBS', 'PPTA', 'DEE', 'CAR', 'CSN', 'ARW', 'HWH', 'IGP', 'NJP', 'BJU', 'BSB', 'WR', 'LTT', 'MAS', 'BPRD', 'SA', 'ADI', 'KGP', 'BTI', 'SLO', 'RU', 'JU', 'ADRA', 'DLI', 'KCG', 'TATA', 'BSR', 'RN', 'JHS', 'NZM', 'ASR', 'BJF', 'ABR', 'NBQ', 'LNL', 'GMO', 'JSME', 'BTE', 'KIR', 'GHY', 'HMH', 'LDH', 'BKN', 'BGS', 'NGP', 'MDU', 'FL', 'YPR', 'SOG', 'PERN', 'ATT', 'MAO', 'BSP', 'GWL', 'KPD', 'DSJ', 'PUNE', 'MMR', 'NYP', 'LKA', 'CSMT', 'MB', 'PNVL', 'TNA', 'LKG', 'LMG', 'DEC', 'SUR', 'BLS', 'MAJN', 'KIUL', 'MS', 'KOTA', 'MDB', 'AGC', 'BQA', 'ROK', 'KRNT', 'JPH', 'R', 'SWM', 'KQR', 'PNP', 'CTC', 'CNB', 'VPT', 'TMQ', 'MMY', 'GKP']

res_40 = maximize_influence_based_on_central_nodes(G.copy(), top_forty_stations)

res_60 = maximize_influence_based_on_central_nodes(G.copy(), top_sixty_stations)

res_100 = maximize_influence_based_on_central_nodes(G.copy(), top_hundred_stations)



"""plot for 40 top nodes"""

plot(res_40, 75, total_loss_)

"""plot for top 60 nodes"""

plot(res_60, 75, total_loss_)

"""plot for top 100 nodes"""

plot(res_100, 75, total_loss_)

def maximize_influence_based_on_central_nodes_greedy(G,nodes):
  edge_set = set()
  for node in nodes:
    edge_set.update(set(G.edges(node)))

  cur_set = set()
  total_loss = 0
  result = []
  
  for edge in edge_set:
      edge_loss = get_edge_loss(edge, cur_set, train_details_map, edge_to_train_map)
      total_loss += edge_loss
      result.append(total_loss)
      try:
        cur_set.update(set(edge_to_train_map[edge])) #add to the set, the list of train destroyed through 
        G.remove_edge(edge[0], edge[1])
      except:
        x = 0
    
  return result

res_central_nodes_greedy = maximize_influence_based_on_central_nodes_greedy(G.copy(), top_hundred_stations)

plot(res_central_nodes_greedy, 75, total_loss_)

bc = nx.betweenness_centrality(g_copy)
sorted_bc = dict(sorted(bc.items(), key=lambda item: item[1], reverse=True))

k_nodes = 60
top_K_stations = list(sorted_bc.keys())[0:k_nodes]

bc_edges = nx.edge_betweenness_centrality(graph_copy,  weight="weight")
sorted_bc_edges = dict(sorted(bc_edges.items(), key=lambda item: item[1], reverse=True))

k_edges = 20000
top_K_links = list(sorted_bc_edges.keys())[0:k_edges]

def maximize_influence_based_on_central_links(G,edges):
  cur_set = set()
  total_loss = 0
  result = []
  
  for edge in edges:
      edge_loss = get_edge_loss(edge, cur_set, train_details_map, edge_to_train_map)
      total_loss += edge_loss
      result.append(total_loss)
      try:
        cur_set.update(set(edge_to_train_map[edge])) #add to the set, the list of train destroyed through 
        G.remove_edge(edge[0], edge[1])
      except:
        x = 0
    
  return result

result_bc_edges = maximize_influence_based_on_central_links(G.copy(), top_K_links )

